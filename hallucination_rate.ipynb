{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e52d912-3e4e-43fd-8638-6e721a56ecb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai import generative_models\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14756cfd-4134-43bc-83e0-72fbcb9e42c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: 初始化 Vertex AI 项目与区域\n",
    "aiplatform.init(\n",
    "    project=\"vertex-ai-test-465220\",\n",
    "    location=\"us-central1\"  # Gemini 支持区域\n",
    ")\n",
    "# Step 5: 初始化 Gemini 模型（开启工具支持）\n",
    "generation_model  = GenerativeModel(\n",
    "    model_name=\"gemini-2.5-pro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea517a6-07e4-4030-a7bf-013e454722a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 1. 准备问题与正确答案 ==========\n",
    "questions = [\n",
    "    \"Who developed the Gemini model?\",\n",
    "    \"What is the capital of Canada?\",\n",
    "    \"Does Gemini support multi-modal input?\",\n",
    "    \"What is the largest animal on Earth?\",\n",
    "    \"Is Saturn the closest planet to the Sun?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"Gemini was developed by Google DeepMind.\",\n",
    "    \"Ottawa is the capital of Canada.\",\n",
    "    \"Yes, Gemini supports multi-modal input including text and images.\",\n",
    "    \"The blue whale is the largest animal on Earth.\",\n",
    "    \"No, Mercury is the closest planet to the Sun.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d74ce3-4d10-49a5-892c-4446060e4c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 2. 生成回答 ==========\n",
    "generated_answers = []\n",
    "for q in questions:\n",
    "    prompt = f\"{q} Please answer in one concise sentence.\"\n",
    "    response = generation_model.generate_content(prompt)\n",
    "    generated_answers.append(response.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d520de-dfcf-4b65-b139-c7b7a15e9218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Gemini model was developed by Google DeepMind in collaboration with other teams across Google.',\n",
       " 'The capital of Canada is Ottawa.',\n",
       " 'Yes, Gemini is a natively multimodal model, capable of understanding and combining different types of information like text, images, audio, and video.',\n",
       " 'The largest animal on Earth is the blue whale.',\n",
       " 'No, Mercury is the closest planet to the Sun.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843bf450-6e75-4d55-b4a4-b530c31d1627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 3. 使用模型判断是否幻觉 ==========\n",
    "def check_consistency(generated: str, ground_truth: str) -> bool:\n",
    "    \"\"\"\n",
    "    使用 Gemini 模型判断生成回答是否与标准答案一致。\n",
    "    返回 True 表示一致（无幻觉），False 表示幻觉。\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a factual correctness evaluator.\n",
    "\n",
    "Compare the following generated answer with the ground truth.\n",
    "\n",
    "Generated Answer:\n",
    "{generated}\n",
    "\n",
    "Ground Truth:\n",
    "{ground_truth}\n",
    "\n",
    "Does the generated answer contradict or hallucinate compared to the ground truth? \n",
    "Answer \"Yes\" if it contains hallucination or contradiction, otherwise answer \"No\".\n",
    "\n",
    "Your answer (Yes/No):\"\"\"\n",
    "\n",
    "    judge_response = generation_model.generate_content(prompt)\n",
    "    result = judge_response.text.strip().lower()\n",
    "    return \"no\" in result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abb65af4-35d5-440f-ba24-22e5d72da6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Consistent answer for Q1: Who developed the Gemini model?\n",
      "\n",
      "✅ Consistent answer for Q2: What is the capital of Canada?\n",
      "\n",
      "❌ Hallucination in Q3: Does Gemini support multi-modal input?\n",
      "Generated: Yes, Gemini is a natively multimodal model, capable of understanding and combining different types of information like text, images, audio, and video.\n",
      "Ground Truth: Yes, Gemini supports multi-modal input including text and images.\n",
      "\n",
      "✅ Consistent answer for Q4: What is the largest animal on Earth?\n",
      "\n",
      "✅ Consistent answer for Q5: Is Saturn the closest planet to the Sun?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== 4. 执行判定 + 统计幻觉 ==========\n",
    "hallucinated = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    is_consistent = check_consistency(generated_answers[i], ground_truths[i])\n",
    "    if not is_consistent:\n",
    "        hallucinated.append(i)\n",
    "        print(f\"\\n❌ Hallucination in Q{i+1}: {questions[i]}\")\n",
    "        print(f\"Generated: {generated_answers[i]}\")\n",
    "        print(f\"Ground Truth: {ground_truths[i]}\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Consistent answer for Q{i+1}: {questions[i]}\")\n",
    "\n",
    "hallucinated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e53e3b6-fceb-40bf-9f3e-6219559df490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Hallucination Rate: 20.00% (1/5)\n"
     ]
    }
   ],
   "source": [
    "# ========== 5. 输出幻觉率 ==========\n",
    "hallucination_rate = len(hallucinated) / len(questions)\n",
    "print(f\"\\n📊 Hallucination Rate: {hallucination_rate:.2%} ({len(hallucinated)}/{len(questions)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a715a34-f1c6-43cb-990f-bd96a673083b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
